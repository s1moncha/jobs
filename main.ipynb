{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4163d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "with open('/Users/simoncha/Desktop/projects/jobs/valid_companies.txt', \"r\") as f:\n",
    "    companies = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e648a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs = []\n",
    "\n",
    "for company in companies[0:2]:\n",
    "    company_slug = company.lower().replace(\" \", \"\").replace(\"-\", \"\").replace(\".\", \"\")\n",
    "    url = f\"https://boards-api.greenhouse.io/v1/boards/{company_slug}/jobs\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Failed for: {company} ({response.status_code})\")\n",
    "            continue\n",
    "\n",
    "        data = response.json()\n",
    "        for job in data.get(\"jobs\", []):\n",
    "            job_info = {\n",
    "                \"company\": company,\n",
    "                \"title\": job.get(\"title\"),\n",
    "                \"location\": job.get(\"location\", {}).get(\"name\"),\n",
    "                \"url\": job.get(\"absolute_url\"),\n",
    "                \"posted\": job.get(\"first_published\")\n",
    "            }\n",
    "            all_jobs.append(job_info)\n",
    "\n",
    "        print(f\"‚úÖ Retrieved {len(data.get('jobs', []))} jobs for {company}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error for {company}: {e}\")\n",
    "\n",
    "# Optional: Print summary\n",
    "print(f\"\\nTotal jobs collected: {len(all_jobs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import ollama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# =========================================================\n",
    "# 1. LOCATION FILTER (US ONLY)\n",
    "# =========================================================\n",
    "\n",
    "us_states = {\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL',\n",
    "    'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT',\n",
    "    'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI',\n",
    "    'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "}\n",
    "\n",
    "us_keywords = ['united states', 'us', 'usa']\n",
    "\n",
    "location_exclusions = [\n",
    "    \"australia\", \"emea\", \"united kingdom\", \"india\", \"ind\",\n",
    "    \"deu\", \"dusseldorf\", \"toronto\", \"mexico\"\n",
    "]\n",
    "\n",
    "us_jobs = []\n",
    "\n",
    "for job in all_jobs:\n",
    "    location = job.get(\"location\", \"\")\n",
    "    if not location:\n",
    "        continue\n",
    "\n",
    "    loc_lower = location.lower()\n",
    "\n",
    "    if any(bad in loc_lower for bad in location_exclusions):\n",
    "        continue\n",
    "\n",
    "    if (\n",
    "        any(kw in loc_lower for kw in us_keywords)\n",
    "        or any(state in location for state in us_states)\n",
    "        or \"remote\" in loc_lower\n",
    "    ):\n",
    "        us_jobs.append(job)\n",
    "\n",
    "print(f\"üá∫üá∏ Found {len(us_jobs)} U.S. or U.S.-Remote jobs.\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. LEXICAL SENIORITY FILTER (IMMEDIATELY AFTER LOCATION)\n",
    "# =========================================================\n",
    "\n",
    "EXCLUDE_TERMS = [\n",
    "    \"vp\", \"vice president\", \"svp\", \"evp\",\n",
    "    \"director\", \"sr director\", \"senior director\",\n",
    "    \"head of\", \"principal\", \"staff\",\n",
    "    \"manager\", \"senior manager\", \"area manager\",\n",
    "    \"executive\", \"recruiter\", \"human resources\", \"hr\", \"senior\"\n",
    "]\n",
    "\n",
    "def normalize_title(title):\n",
    "    title = title.lower()\n",
    "    title = re.sub(r\"[^\\w\\s]\", \" \", title)\n",
    "    title = re.sub(r\"\\s+\", \" \", title).strip()\n",
    "    return title\n",
    "\n",
    "def passes_lexical_filter(title):\n",
    "    norm = normalize_title(title)\n",
    "    return not any(term in norm for term in EXCLUDE_TERMS)\n",
    "\n",
    "lexical_pass_jobs = []\n",
    "lexical_rejected_jobs = []\n",
    "\n",
    "for job in us_jobs:\n",
    "    title = job.get(\"title\", \"\")\n",
    "    if not title:\n",
    "        continue\n",
    "\n",
    "    if passes_lexical_filter(title):\n",
    "        lexical_pass_jobs.append(job)\n",
    "    else:\n",
    "        lexical_rejected_jobs.append(job)\n",
    "\n",
    "print(f\"üö´ Rejected by lexical filter: {len(lexical_rejected_jobs)}\")\n",
    "print(f\"‚úÖ Passed lexical filter: {len(lexical_pass_jobs)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. EMBEDDING SIMILARITY FILTER\n",
    "# =========================================================\n",
    "\n",
    "TARGET_ROLE_DESCRIPTION = \"\"\"\n",
    "Entry level or new graduate role in data science, analytics,\n",
    "computer science, software engineering, data engineering,\n",
    "applied statistics, or machine learning, based in the United States.\n",
    "\"\"\"\n",
    "\n",
    "# =========================================================\n",
    "# 3. EMBEDDING SIMILARITY + AUTO YES / NO ROUTING\n",
    "# =========================================================\n",
    "\n",
    "EMBEDDING_FLOOR = 0.19     # auto-NO\n",
    "AUTO_YES_SCORE = 0.45     # auto-YES\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "titles = []\n",
    "job_refs = []\n",
    "\n",
    "for job in lexical_pass_jobs:\n",
    "    title = job.get(\"title\", \"\")\n",
    "    if title:\n",
    "        titles.append(title)\n",
    "        job_refs.append(job)\n",
    "\n",
    "# Batch embed titles\n",
    "title_embeddings = embedder.encode(\n",
    "    titles,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# Embed target role\n",
    "target_embedding = embedder.encode(\n",
    "    [TARGET_ROLE_DESCRIPTION],\n",
    "    normalize_embeddings=True\n",
    ")[0]\n",
    "\n",
    "# Cosine similarity\n",
    "similarities = np.dot(title_embeddings, target_embedding)\n",
    "\n",
    "# Routing buckets\n",
    "auto_yes_jobs = []\n",
    "llm_candidate_jobs = []\n",
    "embedding_rejected_jobs = []\n",
    "\n",
    "for score, job in zip(similarities, job_refs):\n",
    "    job[\"embedding_score\"] = float(score)\n",
    "\n",
    "    if score < EMBEDDING_FLOOR:\n",
    "        embedding_rejected_jobs.append(job)\n",
    "\n",
    "    elif score >= AUTO_YES_SCORE:\n",
    "        auto_yes_jobs.append(job)\n",
    "\n",
    "    else:\n",
    "        llm_candidate_jobs.append(job)\n",
    "\n",
    "print(f\"üìâ Auto-NO (embedding < {EMBEDDING_FLOOR}): {len(embedding_rejected_jobs)}\")\n",
    "print(f\"‚ö° Auto-YES (embedding ‚â• {AUTO_YES_SCORE}): {len(auto_yes_jobs)}\")\n",
    "print(f\"ü§î Sent to LLM: {len(llm_candidate_jobs)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 4. LLM ARBITRATION (ONLY UNCERTAIN BAND)\n",
    "# =========================================================\n",
    "\n",
    "def should_apply(title):\n",
    "    prompt = f\"\"\"\n",
    "You are helping an upcoming graduate in Statistics decide whether to apply for jobs.\n",
    "\n",
    "CRITERIA:\n",
    "- Target roles related to data science, analytics, computer science, software engineering, data engineering, or applied statistics\n",
    "- Entry-level, new grad, or roles that do NOT require extensive experience\n",
    "- Role must plausibly exist in the United States\n",
    "\n",
    "Respond with ONLY one word:\n",
    "YES or NO\n",
    "\n",
    "Role title:\n",
    "{title}\n",
    "\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "    answer = response[\"message\"][\"content\"].strip().upper()\n",
    "    return \"YES\" if \"YES\" in answer else \"NO\"\n",
    "\n",
    "\n",
    "# Start with auto-YES\n",
    "llm_no_titles = set()\n",
    "yes_jobs = auto_yes_jobs[:]\n",
    "no_jobs = []\n",
    "\n",
    "for i, job in enumerate(llm_candidate_jobs, start=1):\n",
    "    title = job.get(\"title\", \"\")\n",
    "    if not title:\n",
    "        continue\n",
    "\n",
    "    # ---- NEW: skip if already rejected by LLM ----\n",
    "    if title in llm_no_titles:\n",
    "        print(f\"[LLM SKIP] Previously rejected ‚Üí {title}\")\n",
    "        no_jobs.append(job)\n",
    "        continue\n",
    "\n",
    "    decision = should_apply(title)\n",
    "    print(f\"[LLM {i}/{len(llm_candidate_jobs)}] {decision} ‚Üí {title}\")\n",
    "\n",
    "    if decision == \"YES\":\n",
    "        yes_jobs.append(job)\n",
    "    else:\n",
    "        no_jobs.append(job)\n",
    "        llm_no_titles.add(title)   # <-- cache rejection\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. SUMMARY\n",
    "# =========================================================\n",
    "\n",
    "total = len(all_jobs)\n",
    "percent_yes = (len(yes_jobs) / total * 100) if total > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(f\"Total original jobs: {total}\")\n",
    "print(f\"US-filtered jobs: {len(us_jobs)}\")\n",
    "print(f\"Lexical rejected: {len(lexical_rejected_jobs)}\")\n",
    "print(f\"Embedding rejected: {len(embedding_rejected_jobs)}\")\n",
    "print(f\"LLM YES (apply): {len(yes_jobs)}\")\n",
    "print(f\"LLM NO (skip): {len(no_jobs)}\")\n",
    "print(f\"Percent YES overall: {percent_yes:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"company\", \"title\", \"location\", \"url\", \"posted\"]\n",
    "\n",
    "filtered_jobs = [\n",
    "    {k: job.get(k) for k in COLUMNS}\n",
    "    for job in yes_jobs\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"upgrade_{timestamp}.csv\"\n",
    "\n",
    "df = pd.DataFrame(yes_jobs)\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
